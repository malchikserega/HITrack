import requests
import logging
import time
from typing import Dict, List, Optional, Tuple, Set
from datetime import datetime, date
import re
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
import json
import os
from pathlib import Path

logger = logging.getLogger(__name__)

class VulnerabilityDataCollector:
    """
    Collects vulnerability information from various external sources.
    """
    
    def __init__(self, cache_dir: str = None, max_workers: int = 5):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'HITrack-Vulnerability-Scanner/1.0'
        })
        
        # Cache settings
        self.cache_dir = cache_dir or "/tmp/hitrack_cache"
        Path(self.cache_dir).mkdir(exist_ok=True)
        
        # Threading settings
        self.max_workers = max_workers
        
        # CISA KEV cache
        self._cisa_kev_cache = None
        self._cisa_kev_cache_time = None
        self._cisa_kev_lock = threading.Lock()
        
        # Exploit-DB cache
        self._exploit_db_cache = None
        self._exploit_db_cache_time = None
        self._exploit_db_lock = threading.Lock()
        
        # Rate limiting
        self._last_request_time = {}
        self._rate_limit_lock = threading.Lock()
    
    def get_cve_details(self, cve_id: str) -> Optional[Dict]:
        """
        Get detailed information about a CVE from CVE Details.
        
        Args:
            cve_id: The CVE identifier (e.g., 'CVE-2021-44228')
            
        Returns:
            Dictionary with CVE details or None if not found
        """
        try:
            self._rate_limit("cve.circl.lu", 1.0)
            # CVE Details API endpoint
            url = f"https://cve.circl.lu/api/cve/{cve_id}"
            
            response = self.session.get(url, timeout=10)
            response.raise_for_status()
            
            data = response.json()
            
            if not data:
                logger.warning(f"No data returned for {cve_id}")
                return None
            
            # Extract relevant information
            cve_details = {
                'cve_details_score': self._extract_cvss_score(data),
                'cve_details_severity': self._extract_severity(data),
                'cve_details_published_date': self._extract_published_date(data),
                'cve_details_updated_date': self._extract_updated_date(data),
                'cve_details_summary': self._extract_summary(data),
                'cve_details_references': self._extract_references(data),
            }
            
            logger.info(f"Extracted CVE details for {cve_id}: {cve_details}")
            return cve_details
            
        except requests.RequestException as e:
            logger.warning(f"Failed to get CVE details for {cve_id}: {str(e)}")
            return None
        except Exception as e:
            logger.error(f"Error processing CVE details for {cve_id}: {str(e)}")
            return None
    
    def get_exploit_info(self, cve_id: str) -> Optional[Dict]:
        """
        Get exploit information for a CVE from various sources.
        
        Args:
            cve_id: The CVE identifier
            
        Returns:
            Dictionary with exploit information or None if not found
        """
        try:
            exploit_info = {
                'exploit_available': False,
                'exploit_public': False,
                'exploit_verified': False,
                'exploit_links': [],
                # Separate Exploit-DB information
                'exploit_db_available': False,
                'exploit_db_verified': False,
                'exploit_db_count': 0,
                'exploit_db_verified_count': 0,
                'exploit_db_working_count': 0,
                'exploit_db_links': []
            }
            
            # Check CISA KEV first (most authoritative)
            cisa_kev_info = self._check_cisa_kev(cve_id)
            if cisa_kev_info:
                exploit_info.update(cisa_kev_info)
                # If found in CISA KEV, mark as exploited and verified
                exploit_info['exploit_available'] = True
                exploit_info['exploit_verified'] = True
                exploit_info['exploit_public'] = True
                logger.info(f"CVE {cve_id} found in CISA KEV - marking as verified exploit")
            
            # Check Exploit-DB (always check for separate tracking)
            exploit_db_info = self._check_exploit_db(cve_id)
            if exploit_db_info:
                # Store Exploit-DB specific information separately
                exploit_info['exploit_db_available'] = exploit_db_info.get('exploit_available', False)
                exploit_info['exploit_db_verified'] = exploit_db_info.get('exploit_verified', False)
                exploit_info['exploit_db_count'] = exploit_db_info.get('exploit_count', 0)
                exploit_info['exploit_db_verified_count'] = exploit_db_info.get('verified_count', 0)
                exploit_info['exploit_db_working_count'] = exploit_db_info.get('working_count', 0)
                exploit_info['exploit_db_links'] = exploit_db_info.get('links', [])
                
                # Only mark as general exploit if not already marked by CISA KEV
                if not cisa_kev_info:
                    exploit_info['exploit_available'] = exploit_db_info.get('exploit_available', False)
                    exploit_info['exploit_verified'] = exploit_db_info.get('exploit_verified', False)
                    exploit_info['exploit_links'].extend(exploit_db_info.get('links', []))
                
                logger.info(f"CVE {cve_id} found in Exploit-DB - separate tracking enabled")
            
            # Check NVD (for vulnerability information only)
            nvd_info = self._check_nvd(cve_id)
            if nvd_info:
                exploit_info['exploit_links'].extend(nvd_info.get('links', []))
                # Don't mark as exploit based on NVD alone
            
            logger.info(f"Extracted exploit info for {cve_id}: {exploit_info}")
            return exploit_info
            
        except Exception as e:
            logger.error(f"Error getting exploit info for {cve_id}: {str(e)}")
            return None
    
    def _extract_cvss_score(self, data: Dict) -> Optional[float]:
        """Extract CVSS score from CVE data."""
        try:
            # Try different possible field names (old format)
            cvss_fields = ['cvss', 'cvss_score', 'score', 'cvss_v3_score']
            for field in cvss_fields:
                if field in data and data[field]:
                    try:
                        return float(data[field])
                    except (ValueError, TypeError):
                        continue
            
            # Try CVE API v5 format - check both cna and adp containers
            if 'containers' in data and data['containers']:
                containers = data['containers']
                
                # Check cna container first (where CVSS data is usually found)
                if 'cna' in containers and containers['cna']:
                    cna = containers['cna']
                    # Handle both list and dict formats
                    if isinstance(cna, list):
                        cna_items = cna
                    else:
                        cna_items = [cna]
                    
                    for cna_item in cna_items:
                        if isinstance(cna_item, dict) and 'metrics' in cna_item and cna_item['metrics']:
                            metrics = cna_item['metrics']
                            if isinstance(metrics, list) and metrics:
                                for metric in metrics:
                                    if isinstance(metric, dict):
                                        # Try CVSS v3.1 first
                                        if 'cvssV3_1' in metric and metric['cvssV3_1']:
                                            cvss_data = metric['cvssV3_1']
                                            if isinstance(cvss_data, dict) and 'baseScore' in cvss_data:
                                                try:
                                                    return float(cvss_data['baseScore'])
                                                except (ValueError, TypeError):
                                                    pass
                                        # Try CVSS v3.0
                                        elif 'cvssV3_0' in metric and metric['cvssV3_0']:
                                            cvss_data = metric['cvssV3_0']
                                            if isinstance(cvss_data, dict) and 'baseScore' in cvss_data:
                                                try:
                                                    return float(cvss_data['baseScore'])
                                                except (ValueError, TypeError):
                                                    pass
                                        # Try CVSS v2
                                        elif 'cvssV2' in metric and metric['cvssV2']:
                                            cvss_data = metric['cvssV2']
                                            if isinstance(cvss_data, dict) and 'baseScore' in cvss_data:
                                                try:
                                                    return float(cvss_data['baseScore'])
                                                except (ValueError, TypeError):
                                                    pass
                            elif isinstance(metrics, dict):
                                # Try CVSS v3
                                for cvss_version in ['cvssV3_1', 'cvssV3_0']:
                                    if cvss_version in metrics and metrics[cvss_version]:
                                        cvss_data = metrics[cvss_version]
                                        if isinstance(cvss_data, list) and cvss_data:
                                            cvss_item = cvss_data[0]
                                            if 'baseScore' in cvss_item:
                                                try:
                                                    return float(cvss_item['baseScore'])
                                                except (ValueError, TypeError):
                                                    pass
                                        elif isinstance(cvss_data, dict) and 'baseScore' in cvss_data:
                                            try:
                                                return float(cvss_data['baseScore'])
                                            except (ValueError, TypeError):
                                                pass
                                # Try CVSS v2
                                if 'cvssV2' in metrics and metrics['cvssV2']:
                                    cvss_data = metrics['cvssV2']
                                    if isinstance(cvss_data, list) and cvss_data:
                                        cvss_item = cvss_data[0]
                                        if 'baseScore' in cvss_item:
                                            try:
                                                return float(cvss_item['baseScore'])
                                            except (ValueError, TypeError):
                                                pass
                                    elif isinstance(cvss_data, dict) and 'baseScore' in cvss_data:
                                        try:
                                            return float(cvss_data['baseScore'])
                                        except (ValueError, TypeError):
                                            pass
                
                # Check adp container as fallback
                if 'adp' in containers and containers['adp']:
                    adp = containers['adp']
                    if isinstance(adp, list) and adp:
                        for adp_item in adp:
                            if isinstance(adp_item, dict) and 'metrics' in adp_item and adp_item['metrics']:
                                metrics = adp_item['metrics']
                                if isinstance(metrics, list) and metrics:
                                    for metric in metrics:
                                        if isinstance(metric, dict):
                                            # Try CVSS v3.1 first
                                            if 'cvssV3_1' in metric and metric['cvssV3_1']:
                                                cvss_data = metric['cvssV3_1']
                                                if isinstance(cvss_data, dict) and 'baseScore' in cvss_data:
                                                    try:
                                                        return float(cvss_data['baseScore'])
                                                    except (ValueError, TypeError):
                                                        pass
                                            # Try CVSS v3.0
                                            elif 'cvssV3_0' in metric and metric['cvssV3_0']:
                                                cvss_data = metric['cvssV3_0']
                                                if isinstance(cvss_data, dict) and 'baseScore' in cvss_data:
                                                    try:
                                                        return float(cvss_data['baseScore'])
                                                    except (ValueError, TypeError):
                                                        pass
                                            # Try CVSS v2
                                            elif 'cvssV2' in metric and metric['cvssV2']:
                                                cvss_data = metric['cvssV2']
                                                if isinstance(cvss_data, dict) and 'baseScore' in cvss_data:
                                                    try:
                                                        return float(cvss_data['baseScore'])
                                                    except (ValueError, TypeError):
                                                        pass
            
            # Try old format (fallback)
            if 'cvss_v3' in data and data['cvss_v3']:
                if isinstance(data['cvss_v3'], dict) and 'base_score' in data['cvss_v3']:
                    try:
                        return float(data['cvss_v3']['base_score'])
                    except (ValueError, TypeError):
                        pass
            
            return None
        except (ValueError, TypeError):
            return None
    
    def _extract_severity(self, data: Dict) -> Optional[str]:
        """Extract severity from CVE data."""
        try:
            # Try to get severity from CVSS score
            score = self._extract_cvss_score(data)
            if score:
                if score >= 9.0:
                    return 'CRITICAL'
                elif score >= 7.0:
                    return 'HIGH'
                elif score >= 4.0:
                    return 'MEDIUM'
                else:
                    return 'LOW'
            
            # Try direct severity field
            severity_fields = ['severity', 'cvss_severity', 'impact']
            for field in severity_fields:
                if field in data and data[field]:
                    severity = str(data[field]).upper()
                    if severity in ['CRITICAL', 'HIGH', 'MEDIUM', 'LOW']:
                        return severity
            
            # Try CVE API v5 format - check both cna and adp containers
            if 'containers' in data and data['containers']:
                containers = data['containers']
                
                # Check cna container first (where CVSS data is usually found)
                if 'cna' in containers and containers['cna']:
                    cna = containers['cna']
                    # Handle both list and dict formats
                    if isinstance(cna, list):
                        cna_items = cna
                    else:
                        cna_items = [cna]
                    
                    for cna_item in cna_items:
                        if isinstance(cna_item, dict) and 'metrics' in cna_item and cna_item['metrics']:
                            metrics = cna_item['metrics']
                            if isinstance(metrics, list) and metrics:
                                for metric in metrics:
                                    if isinstance(metric, dict):
                                        # Try CVSS v3.1 severity
                                        if 'cvssV3_1' in metric and metric['cvssV3_1']:
                                            cvss_data = metric['cvssV3_1']
                                            if isinstance(cvss_data, dict) and 'baseSeverity' in cvss_data:
                                                severity = str(cvss_data['baseSeverity']).upper()
                                                if severity in ['CRITICAL', 'HIGH', 'MEDIUM', 'LOW']:
                                                    return severity
                                        # Try CVSS v3.0 severity
                                        elif 'cvssV3_0' in metric and metric['cvssV3_0']:
                                            cvss_data = metric['cvssV3_0']
                                            if isinstance(cvss_data, dict) and 'baseSeverity' in cvss_data:
                                                severity = str(cvss_data['baseSeverity']).upper()
                                                if severity in ['CRITICAL', 'HIGH', 'MEDIUM', 'LOW']:
                                                    return severity
                            elif isinstance(metrics, dict):
                                # Try CVSS v3 severity
                                for cvss_version in ['cvssV3_1', 'cvssV3_0']:
                                    if cvss_version in metrics and metrics[cvss_version]:
                                        cvss_data = metrics[cvss_version]
                                        if isinstance(cvss_data, list) and cvss_data:
                                            cvss_item = cvss_data[0]
                                            if 'baseSeverity' in cvss_item:
                                                severity = str(cvss_item['baseSeverity']).upper()
                                                if severity in ['CRITICAL', 'HIGH', 'MEDIUM', 'LOW']:
                                                    return severity
                                        elif isinstance(cvss_data, dict) and 'baseSeverity' in cvss_data:
                                            severity = str(cvss_data['baseSeverity']).upper()
                                            if severity in ['CRITICAL', 'HIGH', 'MEDIUM', 'LOW']:
                                                return severity
                
                # Check adp container as fallback
                if 'adp' in containers and containers['adp']:
                    adp = containers['adp']
                    if isinstance(adp, list) and adp:
                        for adp_item in adp:
                            if isinstance(adp_item, dict) and 'metrics' in adp_item and adp_item['metrics']:
                                metrics = adp_item['metrics']
                                if isinstance(metrics, list) and metrics:
                                    for metric in metrics:
                                        if isinstance(metric, dict):
                                            # Try CVSS v3.1 severity
                                            if 'cvssV3_1' in metric and metric['cvssV3_1']:
                                                cvss_data = metric['cvssV3_1']
                                                if isinstance(cvss_data, dict) and 'baseSeverity' in cvss_data:
                                                    severity = str(cvss_data['baseSeverity']).upper()
                                                    if severity in ['CRITICAL', 'HIGH', 'MEDIUM', 'LOW']:
                                                        return severity
                                            # Try CVSS v3.0 severity
                                            elif 'cvssV3_0' in metric and metric['cvssV3_0']:
                                                cvss_data = metric['cvssV3_0']
                                                if isinstance(cvss_data, dict) and 'baseSeverity' in cvss_data:
                                                    severity = str(cvss_data['baseSeverity']).upper()
                                                    if severity in ['CRITICAL', 'HIGH', 'MEDIUM', 'LOW']:
                                                        return severity
            
            return None
        except (ValueError, TypeError):
            return None
    
    def _extract_published_date(self, data: Dict) -> Optional[date]:
        """Extract published date from CVE data."""
        try:
            date_fields = ['Published', 'published', 'created', 'created_at', 'published_date']
            for field in date_fields:
                if field in data and data[field]:
                    try:
                        date_str = str(data[field])
                        # Try different date formats
                        for fmt in ['%Y-%m-%d', '%Y-%m-%dT%H:%M:%S', '%Y-%m-%dT%H:%M:%SZ']:
                            try:
                                return datetime.strptime(date_str, fmt).date()
                            except ValueError:
                                continue
                    except (ValueError, TypeError):
                        continue
            
            # Try CVE API v5 format
            if 'cveMetadata' in data and data['cveMetadata']:
                metadata = data['cveMetadata']
                if 'datePublished' in metadata and metadata['datePublished']:
                    try:
                        date_str = str(metadata['datePublished'])
                        for fmt in ['%Y-%m-%d', '%Y-%m-%dT%H:%M:%S', '%Y-%m-%dT%H:%M:%SZ']:
                            try:
                                return datetime.strptime(date_str, fmt).date()
                            except ValueError:
                                continue
                    except (ValueError, TypeError):
                        pass
            
            return None
        except (ValueError, TypeError):
            return None
    
    def _extract_updated_date(self, data: Dict) -> Optional[date]:
        """Extract updated date from CVE data."""
        try:
            date_fields = ['Modified', 'modified', 'updated', 'updated_at', 'modified_date']
            for field in date_fields:
                if field in data and data[field]:
                    try:
                        date_str = str(data[field])
                        # Try different date formats
                        for fmt in ['%Y-%m-%d', '%Y-%m-%dT%H:%M:%S', '%Y-%m-%dT%H:%M:%SZ']:
                            try:
                                return datetime.strptime(date_str, fmt).date()
                            except ValueError:
                                continue
                    except (ValueError, TypeError):
                        continue
            
            # Try CVE API v5 format
            if 'cveMetadata' in data and data['cveMetadata']:
                metadata = data['cveMetadata']
                if 'dateUpdated' in metadata and metadata['dateUpdated']:
                    try:
                        date_str = str(metadata['dateUpdated'])
                        for fmt in ['%Y-%m-%d', '%Y-%m-%dT%H:%M:%S', '%Y-%m-%dT%H:%M:%SZ']:
                            try:
                                return datetime.strptime(date_str, fmt).date()
                            except ValueError:
                                continue
                    except (ValueError, TypeError):
                        pass
            
            return None
        except (ValueError, TypeError):
            return None
    
    def _extract_summary(self, data: Dict) -> Optional[str]:
        """Extract summary from CVE data."""
        try:
            summary_fields = ['summary', 'description', 'details', 'overview']
            for field in summary_fields:
                if field in data and data[field]:
                    summary = str(data[field]).strip()
                    if summary:
                        return summary
            
            # Try CVE API v5 format
            if 'containers' in data and data['containers']:
                containers = data['containers']
                if 'cna' in containers and containers['cna']:
                    cna = containers['cna']
                    # Handle both list and dict formats
                    if isinstance(cna, list):
                        cna_items = cna
                    else:
                        cna_items = [cna]
                    
                    for cna_item in cna_items:
                        if isinstance(cna_item, dict) and 'descriptions' in cna_item and cna_item['descriptions']:
                            descriptions = cna_item['descriptions']
                            if isinstance(descriptions, list) and descriptions:
                                for desc in descriptions:
                                    if isinstance(desc, dict) and 'value' in desc:
                                        summary = str(desc['value']).strip()
                                        if summary:
                                            return summary
            
            return None
        except (ValueError, TypeError):
            return None
    
    def _extract_references(self, data: Dict) -> List[str]:
        """Extract references from CVE data."""
        try:
            references = []
            ref_fields = ['references', 'refs', 'links', 'urls']
            
            for field in ref_fields:
                if field in data and data[field]:
                    refs = data[field]
                    if isinstance(refs, list):
                        for ref in refs:
                            if isinstance(ref, dict):
                                # Try different possible URL fields
                                url_fields = ['url', 'link', 'href', 'reference']
                                for url_field in url_fields:
                                    if url_field in ref and ref[url_field]:
                                        url = str(ref[url_field]).strip()
                                        if url and url not in references:
                                            references.append(url)
                                        break
                            elif isinstance(ref, str):
                                url = ref.strip()
                                if url and url not in references:
                                    references.append(url)
            
            # Try CVE API v5 format
            if 'containers' in data and data['containers']:
                containers = data['containers']
                if 'cna' in containers and containers['cna']:
                    cna = containers['cna']
                    # Handle both list and dict formats
                    if isinstance(cna, list):
                        cna_items = cna
                    else:
                        cna_items = [cna]
                    
                    for cna_item in cna_items:
                        if isinstance(cna_item, dict) and 'references' in cna_item and cna_item['references']:
                            refs = cna_item['references']
                            if isinstance(refs, list):
                                for ref in refs:
                                    if isinstance(ref, dict):
                                        if 'url' in ref and ref['url']:
                                            url = str(ref['url']).strip()
                                            if url and url not in references:
                                                references.append(url)
            
            return references
        except (ValueError, TypeError):
            return []
    
    def _check_exploit_db(self, cve_id: str) -> Optional[Dict]:
        """Check Exploit-DB for exploit information."""
        try:
            # Use bulk method for single CVE
            bulk_results = self._check_exploit_db_bulk({cve_id})
            return bulk_results.get(cve_id)
            
        except Exception as e:
            logger.debug(f"Failed to check Exploit-DB for {cve_id}: {str(e)}")
            return None
    
    def _check_github_advisories(self, cve_id: str) -> Optional[Dict]:
        """Check GitHub Security Advisories for exploit information."""
        try:
            # GitHub Security Advisories API requires authentication
            # For now, we'll skip this check as it requires a GitHub token
            # TODO: Implement GitHub token authentication if needed
            logger.debug(f"Skipping GitHub advisories check for {cve_id} - requires authentication")
            return None
            
        except Exception as e:
            logger.debug(f"Failed to check GitHub advisories for {cve_id}: {str(e)}")
            return None
    
    def _check_nvd(self, cve_id: str) -> Optional[Dict]:
        """Check NVD for exploit information."""
        try:
            # Use bulk method for single CVE
            bulk_results = self._check_nvd_bulk({cve_id})
            return bulk_results.get(cve_id)
            
        except Exception as e:
            logger.debug(f"Failed to check NVD for {cve_id}: {str(e)}")
            return None
    
    def _rate_limit(self, domain: str, delay: float = 1.0):
        """Rate limiting per domain."""
        with self._rate_limit_lock:
            now = time.time()
            if domain in self._last_request_time:
                time_since_last = now - self._last_request_time[domain]
                if time_since_last < delay:
                    time.sleep(delay - time_since_last)
            self._last_request_time[domain] = time.time()
    
    def _get_cached_cisa_kev(self) -> Optional[Dict]:
        """Get CISA KEV data with caching."""
        cache_file = Path(self.cache_dir) / "cisa_kev_cache.json"
        cache_time_file = Path(self.cache_dir) / "cisa_kev_cache_time.txt"
        
        # Check if cache exists and is fresh (less than 1 hour old)
        if cache_file.exists() and cache_time_file.exists():
            try:
                cache_time = float(cache_time_file.read_text().strip())
                if time.time() - cache_time < 3600:  # 1 hour cache
                    with open(cache_file, 'r') as f:
                        return json.load(f)
            except:
                pass
        
        return None
    
    def _save_cisa_kev_cache(self, data: Dict):
        """Save CISA KEV data to cache."""
        cache_file = Path(self.cache_dir) / "cisa_kev_cache.json"
        cache_time_file = Path(self.cache_dir) / "cisa_kev_cache_time.txt"
        
        try:
            with open(cache_file, 'w') as f:
                json.dump(data, f)
            with open(cache_time_file, 'w') as f:
                f.write(str(time.time()))
        except Exception as e:
            logger.warning(f"Failed to save CISA KEV cache: {e}")
    
    def _load_cisa_kev_data(self) -> Optional[Dict]:
        """Load CISA KEV data with caching."""
        # Try cache first
        cached_data = self._get_cached_cisa_kev()
        if cached_data:
            logger.info("Using cached CISA KEV data")
            return cached_data
        
        # Fetch fresh data
        try:
            self._rate_limit("cisa.gov", 2.0)  # Be extra respectful to CISA
            url = "https://www.cisa.gov/sites/default/files/feeds/known_exploited_vulnerabilities.json"
            
            response = self.session.get(url, timeout=30)
            response.raise_for_status()
            
            data = response.json()
            
            # Save to cache
            self._save_cisa_kev_cache(data)
            
            logger.info(f"Fetched fresh CISA KEV data: {data.get('count', 0)} vulnerabilities")
            return data
            
        except Exception as e:
            logger.error(f"Failed to load CISA KEV data: {e}")
            return None
    
    def _check_cisa_kev_bulk(self, cve_ids: Set[str]) -> Dict[str, Dict]:
        """Check multiple CVEs against CISA KEV in one operation."""
        results = {}
        
        # Load CISA KEV data once
        kev_data = self._load_cisa_kev_data()
        if not kev_data or 'vulnerabilities' not in kev_data:
            return results
        
        # Create lookup dictionary for O(1) access
        kev_lookup = {}
        for vuln in kev_data['vulnerabilities']:
            cve_id = vuln.get('cveID')
            if cve_id:
                kev_lookup[cve_id] = vuln
        
        # Check each CVE
        for cve_id in cve_ids:
            if cve_id in kev_lookup:
                vuln = kev_lookup[cve_id]
                results[cve_id] = {
                    'cisa_kev_known_exploited': True,
                    'cisa_kev_date_added': vuln.get('dateAdded'),
                    'cisa_kev_vendor_project': vuln.get('vendorProject'),
                    'cisa_kev_product': vuln.get('product'),
                    'cisa_kev_vulnerability_name': vuln.get('vulnerabilityName'),
                    'cisa_kev_short_description': vuln.get('shortDescription'),
                    'cisa_kev_required_action': vuln.get('requiredAction'),
                    'cisa_kev_due_date': vuln.get('dueDate'),
                    'cisa_kev_ransomware_use': vuln.get('knownRansomwareCampaignUse'),
                    'cisa_kev_notes': vuln.get('notes'),
                    'cisa_kev_cwes': vuln.get('cwes', []),
                    'links': [f"https://www.cisa.gov/known-exploited-vulnerabilities-catalog?field_cve={cve_id}"]
                }
        
        return results
    
    def _check_cisa_kev(self, cve_id: str) -> Optional[Dict]:
        """Check CISA KEV catalog for known exploited vulnerabilities."""
        try:
            # Use bulk method for single CVE
            bulk_results = self._check_cisa_kev_bulk({cve_id})
            return bulk_results.get(cve_id)
            
        except Exception as e:
            logger.debug(f"Failed to check CISA KEV for {cve_id}: {str(e)}")
            return None
    
    def _check_exploit_db_bulk(self, cve_ids: Set[str]) -> Dict[str, Dict]:
        """Check multiple CVEs against Exploit-DB using CSV file with memory optimization."""
        results = {}
        
        try:
            # Check cache first
            with self._exploit_db_lock:
                if (self._exploit_db_cache is not None and 
                    self._exploit_db_cache_time is not None and
                    time.time() - self._exploit_db_cache_time < 3600):  # Cache for 1 hour
                    csv_content = self._exploit_db_cache
                    logger.debug("Using cached Exploit-DB CSV data")
                    use_streaming = False
                else:
                    # Download and parse the CSV file from Exploit-DB repository
                    csv_url = "https://gitlab.com/exploit-database/exploitdb/-/raw/main/files_exploits.csv"
                    
                    response = self.session.get(csv_url, timeout=30, stream=True)
                    response.raise_for_status()
                    
                    # For large files, use streaming approach
                    content_length = response.headers.get('content-length')
                    if content_length and int(content_length) > 5 * 1024 * 1024:  # > 5MB
                        logger.info("Large CSV file detected, using streaming approach")
                        use_streaming = True
                        self._exploit_db_cache = None  # Don't cache large files
                        self._exploit_db_cache_time = None
                    elif content_length and int(content_length) > 50 * 1024 * 1024:  # > 50MB
                        logger.info("Very large CSV file detected, using temporary file approach")
                        use_streaming = True
                        self._exploit_db_cache = None
                        self._exploit_db_cache_time = None
                        # Save to temporary file for very large files
                        import tempfile
                        temp_file = tempfile.NamedTemporaryFile(mode='w+b', delete=False)
                        for chunk in response.iter_content(chunk_size=8192):
                            temp_file.write(chunk)
                        temp_file.close()
                        response = open(temp_file.name, 'r')
                        logger.info(f"Saved large CSV to temporary file: {temp_file.name}")
                    else:
                        # For smaller files, cache the content
                        csv_content = response.text
                        self._exploit_db_cache = csv_content
                        self._exploit_db_cache_time = time.time()
                        use_streaming = False
                        logger.debug("Downloaded and cached Exploit-DB CSV data")
            
            if use_streaming:
                # Process file line by line to save memory
                return self._process_exploit_db_streaming(response, cve_ids)
            else:
                # Process cached content
                return self._process_exploit_db_content(csv_content, cve_ids)
            
        except Exception as e:
            logger.error(f"Failed to download or parse Exploit-DB CSV file: {str(e)}")
            return results
    
    def _process_exploit_db_content(self, csv_content: str, cve_ids: Set[str]) -> Dict[str, Dict]:
        """Process cached CSV content."""
        results = {}
        lines = csv_content.split('\n')
        
        # Find header and process
        header_info = self._parse_csv_header(lines)
        if not header_info:
            return results
        
        # Process each line
        for line in lines[1:]:  # Skip header
            if not line.strip():
                continue
            
            self._process_csv_line(line, header_info, cve_ids, results)
            
            # Early exit if we found all CVEs
            if len(results) == len(cve_ids):
                logger.info(f"Found all {len(cve_ids)} CVEs, stopping early")
                break
        
        logger.info(f"Processed Exploit-DB CSV content, found exploits for {len(results)} CVEs")
        return results
    
    def _process_exploit_db_streaming(self, response, cve_ids: Set[str]) -> Dict[str, Dict]:
        """Process CSV file using streaming to save memory."""
        results = {}
        header_found = False
        header_info = None
        lines_processed = 0
        
        # Process file line by line
        for line in response.iter_lines(decode_unicode=True):
            if not line:
                continue
            
            if not header_found:
                # Look for header line
                if 'id,file,description,date_published,author,type,platform,port,date_added,date_updated,verified,codes,raw_url,exploit_url' in line:
                    header_info = self._parse_csv_header([line])
                    header_found = True
                    if not header_info:
                        logger.error("Failed to parse CSV header")
                        break
                    continue
                else:
                    continue  # Skip lines until we find header
            
            # Process data line
            self._process_csv_line(line, header_info, cve_ids, results)
            lines_processed += 1
            
            # Early exit if we found all CVEs
            if len(results) == len(cve_ids):
                logger.info(f"Found all {len(cve_ids)} CVEs after processing {lines_processed} lines, stopping early")
                break
            
            # Log progress for large files
            if lines_processed % 10000 == 0:
                logger.info(f"Processed {lines_processed} lines, found {len(results)} CVEs")
        
        logger.info(f"Processed Exploit-DB CSV stream ({lines_processed} lines), found exploits for {len(results)} CVEs")
        return results
    
    def _parse_csv_header(self, lines: List[str]) -> Optional[Dict]:
        """Parse CSV header and return column indices."""
        for line in lines:
            if 'id,file,description,date_published,author,type,platform,port,date_added,date_updated,verified,codes,raw_url,exploit_url' in line:
                headers = line.split(',')
                return {
                    'codes_index': headers.index('codes') if 'codes' in headers else None,
                    'verified_index': headers.index('verified') if 'verified' in headers else None,
                    'type_index': headers.index('type') if 'type' in headers else None,
                    'id_index': headers.index('id') if 'id' in headers else None
                }
        return None
    
    def _process_csv_line(self, line: str, header_info: Dict, cve_ids: Set[str], results: Dict):
        """Process a single CSV line and update results."""
        try:
            # Split by comma, but handle quoted fields
            fields = self._parse_csv_line(line)
            
            codes_index = header_info['codes_index']
            verified_index = header_info['verified_index']
            type_index = header_info['type_index']
            id_index = header_info['id_index']
            
            if len(fields) <= max(codes_index, verified_index or 0, type_index or 0, id_index or 0):
                return
            
            codes_field = fields[codes_index] if codes_index < len(fields) else ""
            verified_field = fields[verified_index] if verified_index and verified_index < len(fields) else "0"
            type_field = fields[type_index] if type_index and type_index < len(fields) else ""
            exploit_id = fields[id_index] if id_index and id_index < len(fields) else ""
            
            # Check if any of our CVEs are in the codes field
            for cve_id in cve_ids:
                if cve_id.upper() in codes_field.upper():
                    # Check if this is a verified exploit
                    is_verified = verified_field.strip() == "1"
                    
                    # Check if this is a working exploit type
                    is_working_exploit = type_field.lower() in ['exploit', 'dos', 'shellcode']
                    
                    if cve_id not in results:
                        results[cve_id] = {
                            'exploit_available': True,
                            'exploit_public': True,
                            'exploit_verified': is_verified,
                            'links': [],
                            'exploit_count': 0,
                            'verified_count': 0,
                            'working_count': 0
                        }
                    
                    # Update counts
                    results[cve_id]['exploit_count'] += 1
                    if is_verified:
                        results[cve_id]['verified_count'] += 1
                    if is_working_exploit:
                        results[cve_id]['working_count'] += 1
                    
                    # Add exploit URL if available
                    if exploit_id:
                        exploit_url = f"https://www.exploit-db.com/exploits/{exploit_id}"
                        if exploit_url not in results[cve_id]['links']:
                            results[cve_id]['links'].append(exploit_url)
                    
                    logger.debug(f"Found exploit for {cve_id} in Exploit-DB CSV")
        
        except Exception as e:
            logger.debug(f"Error parsing line in Exploit-DB CSV: {str(e)}")
            return
    
    def _check_exploit_db(self, cve_id: str) -> Optional[Dict]:
        """Check a single CVE against Exploit-DB using CSV file."""
        try:
            # Use the bulk method for single CVE
            results = self._check_exploit_db_bulk({cve_id})
            return results.get(cve_id)
        except Exception as e:
            logger.debug(f"Failed to check Exploit-DB for {cve_id}: {str(e)}")
            return None
    
    def _parse_csv_line(self, line: str) -> List[str]:
        """Parse a CSV line, handling quoted fields properly."""
        fields = []
        current_field = ""
        in_quotes = False
        
        for char in line:
            if char == '"':
                in_quotes = not in_quotes
            elif char == ',' and not in_quotes:
                fields.append(current_field)
                current_field = ""
            else:
                current_field += char
        
        # Add the last field
        fields.append(current_field)
        
        return fields
        
        # Use ThreadPoolExecutor for parallel requests
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            future_to_cve = {executor.submit(check_single_cve, cve_id): cve_id for cve_id in cve_ids}
            
            for future in as_completed(future_to_cve):
                cve_id, result = future.result()
                if result:
                    results[cve_id] = result
        
        return results
    
    def _check_nvd_bulk(self, cve_ids: Set[str]) -> Dict[str, Dict]:
        """Check multiple CVEs against NVD efficiently."""
        results = {}
        
        def check_single_cve(cve_id: str) -> Tuple[str, Optional[Dict]]:
            try:
                self._rate_limit("nvd.nist.gov", 0.5)
                url = f"https://services.nvd.nist.gov/rest/json/cves/2.0?cveId={cve_id}"
                
                response = self.session.get(url, timeout=10)
                response.raise_for_status()
                
                data = response.json()
                
                if data.get('totalResults', 0) > 0:
                    # NVD provides vulnerability information, not exploit information
                    # So we'll just return that the CVE exists in NVD
                    return cve_id, {
                        'links': [f"https://nvd.nist.gov/vuln/detail/{cve_id}"]
                    }
                else:
                    return cve_id, None
                    
            except Exception as e:
                logger.debug(f"Failed to check NVD for {cve_id}: {str(e)}")
                return cve_id, None
        
        # Use ThreadPoolExecutor for parallel requests
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            future_to_cve = {executor.submit(check_single_cve, cve_id): cve_id for cve_id in cve_ids}
            
            for future in as_completed(future_to_cve):
                cve_id, result = future.result()
                if result:
                    results[cve_id] = result
        
        return results
    
    def collect_vulnerability_data_bulk(self, cve_ids: List[str]) -> Dict[str, Tuple[Optional[Dict], Optional[Dict]]]:
        """
        Collect vulnerability data for multiple CVEs efficiently.
        
        Args:
            cve_ids: List of CVE identifiers
            
        Returns:
            Dictionary mapping CVE IDs to (cve_details, exploit_info) tuples
        """
        cve_set = set(cve_ids)
        results = {cve_id: (None, None) for cve_id in cve_ids}
        
        logger.info(f"Starting bulk collection for {len(cve_ids)} CVEs")
        
        # Collect CISA KEV data in bulk (most efficient)
        kev_results = self._check_cisa_kev_bulk(cve_set)
        logger.info(f"Found {len(kev_results)} CVEs in CISA KEV")
        
        # Collect exploit data in parallel
        exploit_db_results = self._check_exploit_db_bulk(cve_set)
        nvd_results = self._check_nvd_bulk(cve_set)
        
        # Combine results
        for cve_id in cve_ids:
            exploit_info = {
                'exploit_available': False,
                'exploit_public': False,
                'exploit_verified': False,
                'exploit_links': []
            }
            
            # Add CISA KEV data
            if cve_id in kev_results:
                kev_data = kev_results[cve_id]
                exploit_info.update(kev_data)
                exploit_info['exploit_available'] = True
                exploit_info['exploit_verified'] = True
            
            # Add Exploit-DB data
            if cve_id in exploit_db_results:
                exploit_db_data = exploit_db_results[cve_id]
                exploit_info.update(exploit_db_data)
            
            # Add NVD data
            if cve_id in nvd_results:
                nvd_data = nvd_results[cve_id]
                exploit_info['exploit_links'].extend(nvd_data.get('links', []))
            
            # For now, skip CVE details in bulk mode (too many individual requests)
            # In production, you might want to implement a bulk CVE API or cache
            cve_details = None
            
            results[cve_id] = (cve_details, exploit_info)
        
        logger.info(f"Completed bulk collection for {len(cve_ids)} CVEs")
        return results


def collect_vulnerability_data(cve_id: str) -> Tuple[Optional[Dict], Optional[Dict]]:
    """
    Collect comprehensive vulnerability data from multiple sources.
    
    Args:
        cve_id: The CVE identifier
        
    Returns:
        Tuple of (cve_details, exploit_info) or (None, None) if failed
    """
    collector = VulnerabilityDataCollector()
    
    # Add delay to be respectful to APIs
    time.sleep(1)
    
    cve_details = collector.get_cve_details(cve_id)
    exploit_info = collector.get_exploit_info(cve_id)
    
    return cve_details, exploit_info


def collect_vulnerability_data_bulk(cve_ids: List[str]) -> Dict[str, Tuple[Optional[Dict], Optional[Dict]]]:
    """
    Collect vulnerability data for multiple CVEs efficiently.
    
    Args:
        cve_ids: List of CVE identifiers
        
    Returns:
        Dictionary mapping CVE IDs to (cve_details, exploit_info) tuples
    """
    collector = VulnerabilityDataCollector()
    return collector.collect_vulnerability_data_bulk(cve_ids) 